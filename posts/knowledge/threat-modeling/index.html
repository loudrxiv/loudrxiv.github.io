<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Threat Modeling | A loudrxiv - A website for the academically-stunted</title><meta name=keywords content="Knowledge base,Privacy,Security"><meta name=description content="The first task a person should do when taking steps to protect their privacy and security is to make a threat model.
Defining a threat To make a threat model, we must first define a threat. A common mistake made by people who are just getting into the privacy space is to define the threat as &ldquo;big-tech companies.&rdquo; There is a fundamental problem with this definition:
Why are we not trusting &ldquo;big-tech companies,&rdquo; but then shift our trust to &ldquo;small-tech companies&rdquo;?"><meta name=author content="Tommy"><link rel=canonical href=https://loudrxiv.github.io/posts/knowledge/threat-modeling/><link crossorigin=anonymous href=/assets/css/stylesheet.c5277e43fde8b6dabe803dff75b3c935ba15f1a218d18c0bcbaba3460636ce74.css integrity="sha256-xSd+Q/3ottq+gD3/dbPJNboV8aIY0YwLy6ujRgY2znQ=" rel="preload stylesheet" as=style><noscript><link crossorigin=anonymous href=/css/includes/noscript.30127fa68e36d08f5dd7f9d4e717dac42e729b844672afd0fbcacb0d9e508595.css integrity="sha256-MBJ/po420I9d1/nU5xfaxC5ym4RGcq/Q+8rLDZ5QhZU=" rel="preload stylesheet" as=style></noscript><link rel=icon href=https://loudrxiv.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://loudrxiv.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://loudrxiv.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://loudrxiv.github.io/apple-touch-icon.png><link rel=mask-icon href=https://loudrxiv.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta property="og:title" content="Threat Modeling"><meta property="og:description" content="The first task a person should do when taking steps to protect their privacy and security is to make a threat model.
Defining a threat To make a threat model, we must first define a threat. A common mistake made by people who are just getting into the privacy space is to define the threat as &ldquo;big-tech companies.&rdquo; There is a fundamental problem with this definition:
Why are we not trusting &ldquo;big-tech companies,&rdquo; but then shift our trust to &ldquo;small-tech companies&rdquo;?"><meta property="og:type" content="article"><meta property="og:url" content="https://loudrxiv.github.io/posts/knowledge/threat-modeling/"><meta property="og:image" content="https://loudrxiv.github.io/waving_snail.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-07-18T00:00:00+00:00"><meta property="article:modified_time" content="2023-02-04T16:21:06-05:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://loudrxiv.github.io/waving_snail.png"><meta name=twitter:title content="Threat Modeling"><meta name=twitter:description content="The first task a person should do when taking steps to protect their privacy and security is to make a threat model.
Defining a threat To make a threat model, we must first define a threat. A common mistake made by people who are just getting into the privacy space is to define the threat as &ldquo;big-tech companies.&rdquo; There is a fundamental problem with this definition:
Why are we not trusting &ldquo;big-tech companies,&rdquo; but then shift our trust to &ldquo;small-tech companies&rdquo;?"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Categories","item":"https://loudrxiv.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Knowledge Base","item":"https://loudrxiv.github.io/posts/knowledge/"},{"@type":"ListItem","position":4,"name":"Threat Modeling","item":"https://loudrxiv.github.io/posts/knowledge/threat-modeling/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Threat Modeling","name":"Threat Modeling","description":"The first task a person should do when taking steps to protect their privacy and security is to make a threat model.\nDefining a threat To make a threat model, we must first define a threat. A common mistake made by people who are just getting into the privacy space is to define the threat as \u0026ldquo;big-tech companies.\u0026rdquo; There is a fundamental problem with this definition:\nWhy are we not trusting \u0026ldquo;big-tech companies,\u0026rdquo; but then shift our trust to \u0026ldquo;small-tech companies\u0026rdquo;?","keywords":["Knowledge base","Privacy","Security"],"articleBody":"The first task a person should do when taking steps to protect their privacy and security is to make a threat model.\nDefining a threat To make a threat model, we must first define a threat. A common mistake made by people who are just getting into the privacy space is to define the threat as “big-tech companies.” There is a fundamental problem with this definition:\nWhy are we not trusting “big-tech companies,” but then shift our trust to “small-tech companies”? What happens if those “small-tech companies” turn out to be malicious? What happens when our favorite “small-tech company” becomes successful and grow exponentially? The proper way to define the threat here is the “service provider,” not “big-tech.”\nGenerally, there are four primary threats a person would want to protect themselves from:\nA service provider spying their users Cross site/service tracking and data sharing, a.k.a. “mass surveillance” An app developer spying on users through their malicious software A hacker trying to get into the users’ computers A typical person would have several of these threats in their threat model. Some of these threats may weigh more than others. For example, a software developer would have a hacker stealing their source code, signing keys and secrets as their primary threat, but beyond that they would also want privacy from the websites they visit and so on. Likewise, an average Joe may have their primary threat as mass surveillance and service providers, but beyond that they also need to have decent security to prevent a hacker from stealing their data.\nFor whistleblowers, the threat model is much more extreme. Beyond what is mentioned above, they also need anonymity. Beyond just hiding what they do, what data they have, not getting hacked by hackers or governments, they also have to hide who they are.\nPrivacy from service providers In most setups, our “private” messages, emails, social interactions are typically stored on a server somewhere. The obvious problem with this is that the service provider (or a hacker who has compromised the server) can look into your “private” conversations whenever and however they want, without you ever knowing. This applies to many common services like SMS messaging, Telegram, Discord, and so on.\nWith end-to-end encryption, you can alleviate this issue by encrypting communications between you and your desired recipients before they are even sent to the server. The confidentiality of your messages is guaranteed, so long as the service provider does not have access to the private keys of either party.\nIn practice, the effectiveness of different end-to-end encryption implementations varies. Applications such as Signal run natively on your device, and every copy of the application is the same across different installations. If the service provider were to backdoor their application in an attempt to steal your private keys, that could later be detected using reverse engineering.\nOn the other hand, web-based end-to-end encryption implementations such as Proton Mail’s webmail or Bitwarden’s web vault rely on the server dynamically serving JavaScript code to the browser to handle cryptographic operations. A malicious server could target a specific user and send them malicious JavaScript code to steal their encryption key, and it would be extremely hard for the user to ever notice such a thing. Even if the user does notice the attempt to steal their key, it would be incredibly hard to prove that it is the provider trying to do so, because the server can choose to serve different web clients to different users.\nTherefore, when relying on end-to-end encryption, you should choose to use native applications over web clients whenever possible.\nEven with end-to-end encryption, service providers can still profile you based on metadata, which is typically not protected. While the service provider could not read your messages to see what you’re saying, they can still observe things like who you’re talking to, how often you message them, and what times you’re typically active. Protection of metadata is fairly uncommon, and you should pay close attention to the technical documentation of the software you are using to see if there is any metadata minimization or protection at all, if that is a concern for you.\nProtection from cross site/service tracking You can be tracked across websites and services using some form of identifiers. These are typically:\nYour IP address Browser cookies Your browser fingerprint Data you submit to websites Payment method correlation Your goals should be to segregate your online identities from each other, to blend in with other people, and simply to avoid giving out identifying information to anyone as much as possible.\nInstead of relying on privacy policies (which are promises that could be violated), try to obfuscate your information in such a way that it is very difficult for different providers to correlate data with each other and build a profile on you. This could come in the form of using encryption tools like Cryptomator prior to uploading your data to cloud services, using prepaid cards or cryptocurrency to protect your credit/debit card information, using a VPN to hide your IP address from websites and services on the internet, etc. The privacy policy should only be relied upon as a last resort, when you have exhausted all of your option for true privacy and need to put complete trust in your service provider.\nBear in mind that companies can hide their ownership or share your information with data brokers, even if they are not in the advertising business. Thus, it makes little sense to solely focus on the “ad-tech” industry as a threat in your threat model. Rather, it makes a lot more sense to protect yourself from service providers as a whole, and any kind of corporate surveillance threat that most people are concerned about will be thwarted along with the rest.\nLimiting Public Information The best way to ensure your data is private is to simply not put it out there in the first place. Deleting information you find about yourself online is one of the best first steps you can take to regain your privacy.\nOn sites where you do share information, checking the privacy settings of your account to limit how widely that data is spread is very important. For example, if your accounts have a “private mode,” enable it to make sure your account isn’t being indexed by search engines and can’t be viewed by people you don’t vet beforehand.\nIf you have already submitted your real information to a number of sites which shouldn’t have it, consider employing disinformation tactics such as submitting fictitious information related to the same online identity to make your real information indistinguishable from the false information.\nProtection from malware and hackers You need security to obtain any semblance of privacy: Using tools which appear private is futile if they could easily be exploited by attackers to release your data later.\nWhen it comes to application security, we generally do not (and sometimes cannot) know if the software that we use is malicious, or might one day become malicious. Even with the most trustworthy developers, there is generally no guarantee that their software does not have a serious vulnerability that could later be exploited.\nTo minimize the potential damage that a malicious piece of software can do, you should employ security by compartmentalization. This could come in the form of using different computers for different jobs, using virtual machines to separate different groups of related applications, or using a secure operating system with a strong focus on application sandboxing and mandatory access control.\nMobile operating systems are generally safer than desktop operating systems when it comes to application sandboxing. Apps cannot obtain root access and only have access to system resources which you grant them.\nDesktop operating systems generally lag behind on proper sandboxing. ChromeOS has similar sandboxing properties to Android, and macOS has full system permission control and opt-in (for developers) sandboxing for applications, however these operating systems do transmit identifying information to their respective OEMs. Linux tends to not submit information to system vendors, but it has poor protection against exploits and malicious apps. This can be mitigated somewhat with specialized distributions which make heavy use of virtual machines or containers, such as Qubes OS.\nWeb browsers, email clients, and office applications all typically run untrusted code sent to you from third-parties. Running multiple virtual machines to separate applications like these from your host system as well as each other is one technique you can use to avoid an exploit in these applications from compromising the rest of your system. Technologies like Qubes OS or Microsoft Defender Application Guard on Windows provide convenient methods to do this seamlessly, for example.\nIf you are concerned about physical attacks you should use an operating system with a secure verified boot implementation, such as Android, iOS, ChromeOS, or macOS. You should also make sure that your drive is encrypted, and that the operating system uses a TPM or Secure Enclave or Secure Element for rate limiting attempts to enter the encryption passphrase. You should avoid sharing your computer with people you don’t trust, because most desktop operating systems do not encrypt data separately per-user.\nBad Practices As a beginner, you may often fall into some bad practices while making a threat model. These include:\nSolely focusing on advertising networks instead of service providers as a whole Heavy reliance on privacy policies Blindly shifting trust from one service provider to another Heavy reliance on badness enumeration for privacy instead of systematically solving the problem Blindly trusting open-source software As discussed, focusing solely on advertising networks and relying solely on privacy policies does not make up a sensible threat model. When switching away from a service provider, try to determine what the root problem is and see if your new provider has any technical solution to the problem. For example, you may not like Google Drive as it means giving Google access to all of your data. The underlying problem here is the lack of end to end encryption, which you can solve by using an encryption tool like Cryptomator or by switching to a provider who provides it out of the box like Proton Drive. Blindly switching from Google Drive to a provider who does not provide end to end encryption like the Murena Cloud does not make sense.\nYou should also keep in mind that badness enumeration does not work, cannot work, has never worked, and will never work. While things like ad blockers and antiviruses may help block the low hanging fruits, they can never fully protect you from the threat. On the other hand, they often increase your attack surface and are not worth the security sacrifice. At best, they are merely covenience tools and should not be thought of as part of a defense strategy.\nAnother thing to keep in mind is that open-source software is not automatically private or secure. Malicious code can be sneaked into the package by the developer of the project, contributors, library developers or the person who compiles the code. Beyond that, sometimes, a piece of open-source software may have worse security properties than its proprietary counterpart. An example of this would be traditional Linux desktops lacking verified boot, system integrity protection, or a full system access control for apps when compared to macOS. When doing threat modeling, it is vital that you evaluate the privacy and security properties of each piece of software being used, rather than just blindly trusting it because it is open-source.\n","wordCount":"1913","inLanguage":"en","datePublished":"2022-07-18T00:00:00Z","dateModified":"2023-02-04T16:21:06-05:00","author":{"@type":"Person","name":"Tommy"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://loudrxiv.github.io/posts/knowledge/threat-modeling/"},"publisher":{"@type":"Organization","name":"A loudrxiv - A website for the academically-stunted","logo":{"@type":"ImageObject","url":"https://loudrxiv.github.io/favicon.ico"}}}</script></head><body class=dark id=top><script crossorigin=anonymous src=/assets/js/theme.b20f95bb4da41ef90a2610a557a7000b2649a3f47282ec571676da6fc0427200.js integrity="sha256-sg+Vu02kHvkKJhClV6cACyZJo/RyguxXFnbab8BCcgA="></script><header class=header><div id=progressBar></div><nav class=nav><div class=logo><a href=https://loudrxiv.github.io accesskey=h title="loudRxiv (Alt + H)"><img src=https://loudrxiv.github.io/snail.gif alt aria-label=logo height=30>loudRxiv</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><input id=hamburger-input type=checkbox></input>
<label id=hamburger-menu for=hamburger-input></label><div class=overlay></div><ul id=menu><li><a href=https://loudrxiv.github.io/posts/ title=Categories><span>Categories</span></a></li><li><a href=https://loudrxiv.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://loudrxiv.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://loudrxiv.github.io/resources title=Resources><span>Resources</span></a></li><li><a href=https://tommytran.io/tommy.asc title=PGP><span>PGP</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://tommytran.io/tommy.crt title=S/MIME><span>S/MIME</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://loudrxiv.github.io>Home</a>&nbsp;»&nbsp;<a href=https://loudrxiv.github.io/posts/>Categories</a>&nbsp;»&nbsp;<a href=https://loudrxiv.github.io/posts/knowledge/>Knowledge Base</a></div><h1 class=post-title>Threat Modeling</h1><div class=post-meta><span title='2022-07-18 00:00:00 +0000 UTC'>July 18, 2022</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;1913 words&nbsp;·&nbsp;Tommy&nbsp;|&nbsp;<a href=https://github.com/PrivSec-dev/privsec.dev/blob/main/content/posts/knowledge/Threat%20Modeling.md rel="noopener noreferrer">Suggest Changes</a></div><div class=post-meta><span title="2023-02-04 16:21:06 -0500 -0500"><i>Last updated on February 4, 2023</i></span></div></header><div class="toc side"><details id=toc><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#defining-a-threat aria-label="Defining a threat">Defining a threat</a></li><li><a href=#privacy-from-service-providers aria-label="Privacy from service providers">Privacy from service providers</a></li><li><a href=#protection-from-cross-siteservice-tracking aria-label="Protection from cross site/service tracking">Protection from cross site/service tracking</a></li><li><a href=#limiting-public-information aria-label="Limiting Public Information">Limiting Public Information</a></li><li><a href=#protection-from-malware-and-hackers aria-label="Protection from malware and hackers">Protection from malware and hackers</a></li><li><a href=#bad-practices aria-label="Bad Practices">Bad Practices</a></li></ul></div></details></div><div class=post-content><p>The first task a person should do when taking steps to protect their privacy and security is to make a threat model.</p><h2 id=defining-a-threat>Defining a threat<a hidden class=anchor aria-hidden=true href=#defining-a-threat>#</a></h2><p><img loading=lazy src=/images/cameras-1.jpg alt=Cameras></p><p>To make a threat model, we must first define a threat. A common mistake made by people who are just getting into the privacy space is to define the threat as &ldquo;big-tech companies.&rdquo; There is a fundamental problem with this definition:</p><p>Why are we not trusting &ldquo;big-tech companies,&rdquo; but then shift our trust to &ldquo;small-tech companies&rdquo;? What happens if those &ldquo;small-tech companies&rdquo; turn out to be malicious? What happens when our favorite &ldquo;small-tech company&rdquo; becomes successful and grow exponentially? <strong>The proper way to define the threat here is the &ldquo;service provider,&rdquo; not &ldquo;big-tech.&rdquo;</strong></p><p>Generally, there are four primary threats a person would want to protect themselves from:</p><ul><li>A service provider spying their users</li><li>Cross site/service tracking and data sharing, a.k.a. &ldquo;mass surveillance&rdquo;</li><li>An app developer spying on users through their malicious software</li><li>A hacker trying to get into the users&rsquo; computers</li></ul><p>A typical person would have several of these threats in their threat model. Some of these threats may weigh more than others. For example, a software developer would have a hacker stealing their source code, signing keys and secrets as their primary threat, but beyond that they would also want privacy from the websites they visit and so on. Likewise, an average Joe may have their primary threat as mass surveillance and service providers, but beyond that they also need to have decent security to prevent a hacker from stealing their data.</p><p>For whistleblowers, the threat model is much more extreme. Beyond what is mentioned above, they also need anonymity. Beyond just hiding what they do, what data they have, not getting hacked by hackers or governments, they also have to hide who they are.</p><h2 id=privacy-from-service-providers>Privacy from service providers<a hidden class=anchor aria-hidden=true href=#privacy-from-service-providers>#</a></h2><p>In most setups, our &ldquo;private&rdquo; messages, emails, social interactions are typically stored on a server somewhere. The obvious problem with this is that the service provider (or a hacker who has compromised the server) can look into your &ldquo;private&rdquo; conversations whenever and however they want, without you ever knowing. This applies to many common services like SMS messaging, Telegram, Discord, and so on.</p><p>With end-to-end encryption, you can alleviate this issue by encrypting communications between you and your desired recipients before they are even sent to the server. The confidentiality of your messages is guaranteed, so long as the service provider does not have access to the private keys of either party.</p><p>In practice, the effectiveness of different end-to-end encryption implementations varies. Applications such as Signal run natively on your device, and every copy of the application is the same across different installations. If the service provider were to backdoor their application in an attempt to steal your private keys, that could later be detected using reverse engineering.</p><p>On the other hand, web-based end-to-end encryption implementations such as Proton Mail&rsquo;s webmail or Bitwarden&rsquo;s web vault rely on the server dynamically serving JavaScript code to the browser to handle cryptographic operations. A malicious server could target a specific user and send them malicious JavaScript code to steal their encryption key, and it would be extremely hard for the user to ever notice such a thing. Even if the user does notice the attempt to steal their key, it would be incredibly hard to prove that it is the provider trying to do so, because the server can choose to serve different web clients to different users.</p><p>Therefore, when relying on end-to-end encryption, you should choose to use native applications over web clients whenever possible.</p><p>Even with end-to-end encryption, service providers can still profile you based on <strong>metadata</strong>, which is typically not protected. While the service provider could not read your messages to see what you&rsquo;re saying, they can still observe things like who you&rsquo;re talking to, how often you message them, and what times you&rsquo;re typically active. Protection of metadata is fairly uncommon, and you should pay close attention to the technical documentation of the software you are using to see if there is any metadata minimization or protection at all, if that is a concern for you.</p><h2 id=protection-from-cross-siteservice-tracking>Protection from cross site/service tracking<a hidden class=anchor aria-hidden=true href=#protection-from-cross-siteservice-tracking>#</a></h2><p>You can be tracked across websites and services using some form of identifiers. These are typically:</p><ul><li>Your IP address</li><li>Browser cookies</li><li>Your browser fingerprint</li><li>Data you submit to websites</li><li>Payment method correlation</li></ul><p>Your goals should be to segregate your online identities from each other, to blend in with other people, and simply to avoid giving out identifying information to anyone as much as possible.</p><p>Instead of relying on privacy policies (which are promises that could be violated), try to obfuscate your information in such a way that it is very difficult for different providers to correlate data with each other and build a profile on you. This could come in the form of using encryption tools like Cryptomator prior to uploading your data to cloud services, using prepaid cards or cryptocurrency to protect your credit/debit card information, using a VPN to hide your IP address from websites and services on the internet, etc. The privacy policy should only be relied upon as a last resort, when you have exhausted all of your option for true privacy and need to put complete trust in your service provider.</p><p>Bear in mind that companies can hide their ownership or share your information with data brokers, even if they are not in the advertising business. Thus, it makes little sense to solely focus on the &ldquo;ad-tech&rdquo; industry as a threat in your threat model. Rather, it makes a lot more sense to protect yourself from service providers as a whole, and any kind of corporate surveillance threat that most people are concerned about will be thwarted along with the rest.</p><h2 id=limiting-public-information>Limiting Public Information<a hidden class=anchor aria-hidden=true href=#limiting-public-information>#</a></h2><p>The best way to ensure your data is private is to simply not put it out there in the first place. Deleting information you find about yourself online is one of the best first steps you can take to regain your privacy.</p><p>On sites where you do share information, checking the privacy settings of your account to limit how widely that data is spread is very important. For example, if your accounts have a &ldquo;private mode,&rdquo; enable it to make sure your account isn&rsquo;t being indexed by search engines and can&rsquo;t be viewed by people you don&rsquo;t vet beforehand.</p><p>If you have already submitted your real information to a number of sites which shouldn&rsquo;t have it, consider employing disinformation tactics such as submitting fictitious information related to the same online identity to make your real information indistinguishable from the false information.</p><h2 id=protection-from-malware-and-hackers>Protection from malware and hackers<a hidden class=anchor aria-hidden=true href=#protection-from-malware-and-hackers>#</a></h2><p><img loading=lazy src=/images/motherboard-1.jpg alt=Motherboard></p><p>You need security to obtain any semblance of privacy: <strong>Using tools which appear private is futile if they could easily be exploited by attackers to release your data later.</strong></p><p>When it comes to application security, we generally do not (and sometimes cannot) know if the software that we use is malicious, or might one day become malicious. Even with the most trustworthy developers, there is generally no guarantee that their software does not have a serious vulnerability that could later be exploited.</p><p>To minimize the potential damage that a malicious piece of software can do, you should employ security by compartmentalization. This could come in the form of using different computers for different jobs, using virtual machines to separate different groups of related applications, or using a secure operating system with a strong focus on application sandboxing and mandatory access control.</p><p>Mobile operating systems are generally safer than desktop operating systems when it comes to application sandboxing. Apps cannot obtain root access and only have access to system resources which you grant them.</p><p>Desktop operating systems generally lag behind on proper sandboxing. ChromeOS has similar sandboxing properties to Android, and macOS has full system permission control and opt-in (for developers) sandboxing for applications, however these operating systems do transmit identifying information to their respective OEMs. Linux tends to not submit information to system vendors, but it has poor protection against exploits and malicious apps. This can be mitigated somewhat with specialized distributions which make heavy use of virtual machines or containers, such as Qubes OS.</p><p>Web browsers, email clients, and office applications all typically run untrusted code sent to you from third-parties. Running multiple virtual machines to separate applications like these from your host system as well as each other is one technique you can use to avoid an exploit in these applications from compromising the rest of your system. Technologies like Qubes OS or Microsoft Defender Application Guard on Windows provide convenient methods to do this seamlessly, for example.</p><p>If you are concerned about physical attacks you should use an operating system with a secure verified boot implementation, such as Android, iOS, ChromeOS, or macOS. You should also make sure that your drive is encrypted, and that the operating system uses a TPM or Secure <a href=https://support.apple.com/guide/security/secure-enclave-sec59b0b31ff/1/web/1>Enclave</a> or <a href=https://developers.google.com/android/security/android-ready-se>Secure Element</a> for rate limiting attempts to enter the encryption passphrase. You should avoid sharing your computer with people you don&rsquo;t trust, because most desktop operating systems do not encrypt data separately per-user.</p><h2 id=bad-practices>Bad Practices<a hidden class=anchor aria-hidden=true href=#bad-practices>#</a></h2><p>As a beginner, you may often fall into some bad practices while making a threat model. These include:</p><ul><li>Solely focusing on advertising networks instead of service providers as a whole</li><li>Heavy reliance on privacy policies</li><li>Blindly shifting trust from one service provider to another</li><li>Heavy reliance on badness enumeration for privacy instead of systematically solving the problem</li><li>Blindly trusting open-source software</li></ul><p>As discussed, focusing solely on advertising networks and relying solely on privacy policies does not make up a sensible threat model. When switching away from a service provider, try to determine what the root problem is and see if your new provider has any technical solution to the problem. For example, you may not like Google Drive as it means giving Google access to all of your data. The underlying problem here is the lack of end to end encryption, which you can solve by using an encryption tool like Cryptomator or by switching to a provider who provides it out of the box like Proton Drive. Blindly switching from Google Drive to a provider who does not provide end to end encryption like the Murena Cloud does not make sense.</p><p>You should also keep in mind that <a href=/knowledge/badness-enumeration/>badness enumeration does not work, cannot work, has never worked, and will never work</a>. While things like ad blockers and antiviruses may help block the low hanging fruits, they can never fully protect you from the threat. On the other hand, they often increase your attack surface and are not worth the security sacrifice. At best, they are merely covenience tools and should not be thought of as part of a defense strategy.</p><p>Another thing to keep in mind is that open-source software is not automatically private or secure. Malicious code can be sneaked into the package by the developer of the project, contributors, library developers or the person who compiles the code. Beyond that, sometimes, a piece of open-source software may have worse security properties than its proprietary counterpart. An example of this would be traditional Linux desktops lacking verified boot, system integrity protection, or a full system access control for apps when compared to macOS. When doing threat modeling, it is vital that you evaluate the privacy and security properties of each piece of software being used, rather than just blindly trusting it because it is open-source.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://loudrxiv.github.io/tags/knowledge-base/>Knowledge base</a></li><li><a href=https://loudrxiv.github.io/tags/privacy/>Privacy</a></li><li><a href=https://loudrxiv.github.io/tags/security/>Security</a></li></ul><nav class=paginav><a class=prev href=https://loudrxiv.github.io/posts/knowledge/multi-factor-authentication/><span class=title>« Prev</span><br><span>Multi-factor Authentication</span></a></nav></footer></article></main><footer class=footer><span><a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA 4.0</a></span>
<span>- Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer">Hugo</a> &
        <a href=https://github.com/Wonderfall/hugo-WonderMod/ rel=noopener>WonderMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script defer crossorigin=anonymous src=/assets/js/papermod.7ea300eda6d3653624a576fbc095ccd8a0c2977756acbe5de4114132a72cc7fa.js integrity="sha256-fqMA7abTZTYkpXb7wJXM2KDCl3dWrL5d5BFBMqcsx/o="></script></body></html>